# Anime Desktop Waifu

A local-first desktop AI companion with a Live2D anime avatar that reacts visually to your interactions. Designed to be a calm, quiet presence on your desktop â€” not an aggressive chatbot.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Platform](https://img.shields.io/badge/platform-Windows-lightgrey.svg)
![Node](https://img.shields.io/badge/node-%3E%3D18.0.0-green.svg)

---

## âœ¨ What Is This?

Anime Desktop Waifu is a desktop companion that combines:
- A **local AI brain** running on your machine
- A **Live2D anime avatar** that responds visually
- **Voice responses** (optional, uses system text-to-speech)
- **Memory** that remembers things you tell it

It's designed to feel like a quiet friend who sits on your desktop, not a hyperactive assistant that interrupts you constantly.

### Why This Exists

Most AI companions are either:
- Cloud-only (privacy concerns, requires internet)
- Text-only (no personality or presence)
- Designed to maximize engagement (annoying)

This project takes a different approach: **your companion, your rules, your machine**.

---

## ğŸ¯ Key Features

### ğŸ§  Local & Hybrid AI

Your conversations stay on your machine by default.

- **Local Mode**: Uses Ollama to run AI models entirely offline
- **Cloud Mode**: Optional Gemini API integration when you want it
- **Your Choice**: Switch between local-only, cloud-preferred, or hybrid modes anytime

No internet required for basic operation.

### ğŸ­ Live2D Anime Avatar

A visual companion that reacts to your conversation.

- Responds to your messages with expressions and motions
- Follows your cursor for a sense of awareness
- Reacts to interaction (try giving her a gentle boop!)
- **Drag Mode**: Move her anywhere on your screen using the toggle menu
- Transparent overlay that sits on your desktop

The avatar is a visual layer â€” she displays what the AI is "feeling," but she's not the AI itself.

### ğŸ—£ï¸ Voice Responses

Optional spoken responses to messages.

- Uses your system's built-in text-to-speech
- Toggle voice on/off at any time
- Adjustable voice selection and speed

> **Note**: System TTS sounds robotic. Anime-style neural voices are planned for future updates.

### ğŸ’¾ Intelligent Memory

Remembers things naturally, forgets gracefully.

- **Session Memory**: Keeps track of your current conversation
- **Long-term Facts**: Remembers important things you tell it
- **Confidence-based**: Facts it's unsure about fade over time
- **Contradiction Handling**: Updates beliefs when you correct it

Your data is stored locally in simple JSON files.

### âš™ï¸ User Control

You decide how the companion behaves.

- Toggle avatar visibility
- Toggle voice responses
- **Drag vs. Interact Mode**: Toggle between moving the window or interacting with the avatar
- Switch AI modes (local/cloud/hybrid)
- Adjust response length and behavior
- All settings accessible from the settings panel

---

## ğŸ“¸ Screenshots

<table>
  <tr>
    <td align="center">
      <img src="docs/screenshots/chat-window.png" alt="Main Chat Window" width="280"/>
      <br/>
      <b>Chat Window</b>
      <br/>
      <em>Clean interface for conversation</em>
    </td>
    <td align="center">
      <img src="docs/screenshots/settings-panel.png" alt="Settings Panel" width="280"/>
      <br/>
      <b>Settings Panel</b>
      <br/>
      <em>AI mode, voice, and avatar controls</em>
    </td>
  </tr>
</table>

<p align="center">
  <img src="docs/screenshots/avatar-overlay.png" alt="Live2D Avatar Overlay" width="400"/>
  <br/>
  <b>Live2D Avatar Overlay</b>
  <br/>
  <em>æ€äººå°å…” (Killer Bunny) â€” Transparent desktop companion</em>
</p>

---

## ğŸš€ Installation (For Everyone)

Don't worry if you're not technical â€” follow these steps carefully and you'll be fine.

### Step 1: Install Node.js

1. Go to [nodejs.org](https://nodejs.org/)
2. Download the **LTS** version (the one that says "Recommended")
3. Run the installer and click "Next" through everything
4. Restart your computer after installation

### Step 2: Install Python (Required for Voice)

> **Note**: If you don't want voice features, you can skip this step. The app will work without voice.

1. Go to [python.org/downloads](https://www.python.org/downloads/)
2. Download Python 3.10 or newer
3. **Important**: During installation, check the box that says **"Add Python to PATH"**
4. Complete the installation

### Step 3: Download This Project

**Option A: Download as ZIP**
1. Click the green "Code" button on this page
2. Click "Download ZIP"
3. Extract the ZIP to a folder you'll remember (like `Documents\AnimeWaifu`)

**Option B: Use Git** (if you have it installed)
```bash
git clone https://github.com/Lokesh-shiva/Anime-desktop-waifu.git
cd Anime-desktop-waifu
```

### Step 4: Install Dependencies

1. Open the folder where you extracted/cloned the project
2. Hold `Shift` and right-click in the folder
3. Click "Open PowerShell window here" (or "Open in Terminal")
4. Run these commands:

```bash
# Install Node.js dependencies
npm install

# Install Python dependencies for voice (optional but recommended)
pip install -r tts/requirements.txt
```

### Step 5: Start the App

In the same terminal window, type:

```bash
npm start
```

The app should open! ğŸ‰

### First Run Notes

- The first launch may take a few extra seconds
- Internet is only needed if you want to use cloud AI features
- The avatar may take a moment to load
- If something looks wrong, try closing and reopening the app
- **Voice not working?** Make sure Python is installed and you ran `pip install -r tts/requirements.txt`

### Configuring the AI Brain

The app needs an AI to generate responses. You have three options:

#### Option A: Local Only (Ollama) â€” Fully Offline

1. Download and install [Ollama](https://ollama.ai/)
2. Open a terminal and run:
   ```bash
   ollama pull phi4-mini:3.8b
   ```
3. Ollama runs in the background automatically
4. In the app, select **"Local Only"** in the settings

> âœ… No internet required after setup. Your conversations stay on your machine.

#### Option B: Cloud Only (Gemini API) â€” Requires Internet

1. Go to [Google AI Studio](https://aistudio.google.com/apikey)
2. Create a free API key
3. Open the app and go to Settings (âš™ï¸ icon)
4. Paste your API key in the **API Key** field
5. Select **"Cloud Only"** in the settings

> âš ï¸ Requires internet. Conversations are sent to Google's servers.

#### Option C: Cloud with Fallback (Recommended for Most Users)

1. Set up Gemini API key (see Option B)
2. Optionally install Ollama (see Option A)
3. Select **"Cloud (fallback)"** in the settings

> This uses cloud when available, falls back to local if offline or if cloud fails.

---

## ğŸ› ï¸ Installation (For Developers)

### Requirements

- **Node.js**: v18.0.0 or higher recommended
- **npm**: Comes with Node.js
- **Electron**: v28.x (installed automatically via npm)
- **Python**: 3.10+ (required for voice features)
- **OS**: Windows 10/11 (primary support), other platforms untested

### Voice Dependencies (Python)

```bash
# System TTS (required for voice)
pip install -r tts/requirements.txt
```

This installs: `fastapi`, `uvicorn`, `pyttsx3`, `soundfile`, `numpy`

For **Neural TTS (Experimental)**:
```bash
pip install styletts2
```
> âš ï¸ StyleTTS2 requires additional setup and a GPU is recommended. See [StyleTTS2 docs](https://github.com/yl4579/StyleTTS2) for details.

### Optional: Local LLM with Ollama

For fully offline AI:

1. Install [Ollama](https://ollama.ai/)
2. Pull a model: `ollama pull phi4-mini:3.8b`
3. Ollama runs in the background automatically

If Ollama isn't running, the app will fall back to cloud mode (if configured).

### Project Structure

```
Anime-desktop-waifu/
â”œâ”€â”€ main.js              # Electron main process
â”œâ”€â”€ preload.js           # Preload scripts for IPC
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.html       # Main window
â”‚   â”œâ”€â”€ renderer.js      # UI logic
â”‚   â”œâ”€â”€ styles.css       # Styling
â”‚   â”œâ”€â”€ avatar/          # Live2D integration
â”‚   â”œâ”€â”€ llm/             # AI provider routing
â”‚   â”œâ”€â”€ memory/          # Fact storage and recall
â”‚   â”œâ”€â”€ presence/        # Awareness features
â”‚   â”œâ”€â”€ state-machine.js # Conversation state
â”‚   â”œâ”€â”€ settings.js      # User preferences
â”‚   â””â”€â”€ voice/           # TTS integration
â”œâ”€â”€ 2D_Livemodel/        # Live2D model assets
â””â”€â”€ tts/                 # TTS server scripts
```

### Running in Development

```bash
npm start
```

Electron will open with DevTools available (`Ctrl+Shift+I`).

---

## ğŸ”Š How Voice Works

Voice is completely optional and can be toggled at any time.

### Current Implementation

- Uses your operating system's built-in text-to-speech engine
- On Windows, this is Microsoft SAPI voices
- Voice selection available in settings
- Adjustable speaking rate

### Honest Expectations

**What it sounds like now**: Robotic. Functional, but clearly synthetic. This is a limitation of system TTS, not something we can fix directly.

**What's planned**: We're exploring anime-style neural TTS solutions. These would sound more natural and expressive, but they're still in development.

### Why Not Just Include Better Voices?

- High-quality neural TTS requires significant resources
- We want to keep the app lightweight and local-first
- Bundling voice models would dramatically increase download size

For now, system TTS is a reasonable trade-off. Better voices are on the roadmap.

---

## ğŸ—ï¸ Architecture Overview

Here's how the pieces fit together:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Your Desktop                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚   Avatar     â”‚â—„â”€â”€â”€â”€â”‚     State Machine        â”‚     â”‚
â”‚   â”‚  (Live2D)    â”‚     â”‚  (emotions, reactions)   â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                           â”‚                    â”‚
â”‚         â”‚                           â”‚                    â”‚
â”‚         â–¼                           â”‚                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚    Voice     â”‚â—„â”€â”€â”€â”€â”‚       AI Brain           â”‚     â”‚
â”‚   â”‚   (TTS)      â”‚     â”‚   (Ollama / Gemini)      â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                      â”‚                   â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                        â”‚         Memory             â”‚   â”‚
â”‚                        â”‚  (facts, conversation)     â”‚   â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The AI Brain

The core intelligence. Processes your messages and generates responses. Can run locally (Ollama) or in the cloud (Gemini API).

### The Memory System

Stores what the companion knows about you. Facts have confidence scores â€” things she's sure about stick around, uncertain things fade naturally.

### The State Machine

Tracks the current emotional and conversational state. Decides how the companion should react based on context.

### The Avatar

A visual puppet. Receives instructions from the state machine about what expression to show. She doesn't "think" â€” she displays.

### Voice (TTS)

Speaks the AI's responses aloud. Completely optional. Works independently of everything else.

---

## ğŸ’­ Project Philosophy

### Calm Over Clever

This isn't designed to impress you with how smart it is. It's designed to be a quiet presence that's there when you want it.

### User Control, Always

Every feature can be toggled. Nothing happens without your input. No notifications, no interruptions, no "engagement optimization."

### Privacy by Default

Your conversations are yours. Local-first means no server logs, no training data collection, no third-party access to your chats.

### Presence Over Gimmicks

The avatar isn't here to sell you on AI. She's here to give the companion a face, a presence, something that feels like it's *there*.

### Honest About Limitations

We don't pretend system TTS sounds good. We don't claim the AI is sentient. We build what works and are upfront about what doesn't.

---

## ğŸ—ºï¸ Roadmap

These features are planned but not yet implemented:

| Feature | Status | Description |
|---------|--------|-------------|
| Anime-style Neural TTS | ğŸ”¬ Research | Higher quality, more expressive voices |
| Push-to-Talk Input | ğŸ“‹ Planned | Speak to your companion instead of typing |
| More Avatar Expressions | ğŸ“‹ Planned | Richer emotional range |
| Performance Optimizations | ğŸ“‹ Planned | Lower CPU/memory usage |
| Cross-platform Support | ğŸ¤” Considering | macOS and Linux builds |

Want to help with any of these? Contributions welcome!

---

## âš ï¸ Known Limitations

Being honest about what doesn't work (yet):

### Voice Quality
System TTS sounds robotic. This is a fundamental limitation of built-in voices, not something the app does wrong. Better voices require neural TTS, which is on the roadmap.

### Speech Input
No speech-to-text yet. You have to type your messages. Push-to-talk is planned for the future.

### Avatar Expressions
The expressiveness depends on the Live2D model. Some models have limited motion/expression parameters. We work with what the model provides.

### Platform Support
Only tested on Windows. It *might* work on macOS/Linux, but there are no guarantees.

### Memory Size
Long-term memory is stored in local files. Very long-term usage may accumulate large memory files. Cleanup tools are planned.

---

## ğŸ“„ License

This project is released under the **MIT License**. See [LICENSE](LICENSE) for details.

You're free to use, modify, and distribute this project. Just keep the license notice intact.

---

## ğŸ™ Credits

### Live2D

This project uses the [pixi-live2d-display](https://github.com/guansss/pixi-live2d-display) library for Live2D integration.

#### Included Model: æ€äººå°å…” (Killer Bunny)

The Live2D model included in this project is **æ€äººå°å…”** (Killer Bunny), created by:

- **Studio**: [å¤§é¹…çŒ«å·¥ä½œå®¤ (Daemao Studio)](https://daemao.top/)
- **Modeler**: AçŒ«çŒ«
- **Bilibili**: [Daemao Studio](https://space.bilibili.com/529570436)

**Usage Terms** (per the original license):
- âŒ No redistribution, resale, or re-uploading
- âŒ No commercial use without authorization
- âŒ No modification of textures or defacing the character
- âœ… Personal use for videos, streaming, and VTuber activities is permitted
- âœ… Fan works and derivative creations are allowed

Please respect the creators' terms. If you want to support them or purchase the full version, visit their [official store](https://daemao.huotan.com/) or [Afdian](https://afdian.net/a/daemao).

**Important**: Live2D models are subject to their own licenses. Always check the license of any Live2D model you use.

### Open Source Libraries

- [Electron](https://www.electronjs.org/) â€” Desktop app framework
- [PixiJS](https://pixijs.com/) â€” 2D rendering engine
- [pixi-live2d-display](https://github.com/guansss/pixi-live2d-display) â€” Live2D for PixiJS
- [Ollama](https://ollama.ai/) â€” Local LLM runtime

### AI Providers

- [Ollama](https://ollama.ai/) â€” Local AI models
- [Google Gemini](https://ai.google.dev/) â€” Cloud AI (optional)

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

### Reporting Issues

Found a bug? Please [open an issue](https://github.com/Lokesh-shiva/Anime-desktop-waifu/issues) with:
- What you expected to happen
- What actually happened
- Steps to reproduce
- Your system info (Windows version, Node version)

### Suggesting Features

Have an idea? Open an issue with the "enhancement" label. Describe:
- What problem it solves
- How you imagine it working
- Any alternatives you considered

### Contributing Code

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/your-feature`)
3. Make your changes
4. Test thoroughly
5. Submit a pull request

Please keep contributions focused and well-documented. Large changes should be discussed in an issue first.

### Code Style

- Keep it readable over clever
- Comment non-obvious logic
- Follow existing patterns in the codebase

---

## ğŸ’¬ Support

Having trouble? Here's what to try:

1. **Check the issues** â€” Someone might have had the same problem
2. **Restart the app** â€” Sometimes that's all it takes
3. **Reinstall dependencies** â€” Delete `node_modules` and run `npm install` again
4. **Open an issue** â€” If nothing else works, describe your problem in detail

---

<p align="center">
  <i>Made with care for people who want a quiet companion on their desktop.</i>
</p>
